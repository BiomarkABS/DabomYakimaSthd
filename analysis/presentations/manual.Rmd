---
title: "Using DABOM for Yakima Steelhead"
author:
  - Kevin See:
      email: Kevin.See@merck.com
      institute: [biomark]
      correspondence: true
  - Mike Ackerman:
      email: Mike.Ackerman@merck.com
      institute: [biomark]
institute:
  - biomark: Biomark, Inc. 705 South 8th St., Boise, Idaho, 83702, USA
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    bookdown::html_document2:
      fig_caption: yes
      fig_height: 6
      fig_width: 6
      toc: yes
      toc_depth: 3
      toc_float:
        collapsed: yes
        smooth_scroll: yes
      theme: simplex
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks.lua
      - --lua-filter=../templates/pagebreak.lua
    bookdown::pdf_document2:
      fig_caption: yes
      fig_height: 5
      fig_width: 6
      toc: yes
      includes:
        in_header: ../templates/header_ABS.tex
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks2.lua
      - --lua-filter=../templates/pagebreak.lua
    bookdown::word_document2:
      fig_caption: yes
      fig_height: 4
      fig_width: 6
      toc: yes
      reference_docx: "../templates/ReportTemplate.docx" # Insert path for the DOCX file
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks.lua
      - --lua-filter=../templates/pagebreak.lua
bibliography:
# - ../paper/packages.bib
- ../paper/references.bib
csl: "../templates/american-fisheries-society.csl" # Insert path for the bib-style
abstract: |
  This manual contains the instructions to run the DABOM model for steelhead in the Yakima basin.
keywords: |
  keyword 1; keyword 2; keyword 3
highlights: |
  These are the highlights.
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = TRUE,
  comment = "#>"
)

library(knitr)
```


# Introduction

This manual describes how to run the **D**am **A**dult **B**ranch **O**ccupancy **M**odel ([DABOM](https://github.com/KevinSee/DABOM)) for steelhead crossing over Prosser Dam and into the Yakima River. We start by describing how to query [PTAGIS](https://www.ptagis.org/) to get all detections of adults at relevant observation sites (e.g., weirs, PIT tag arrays, etc.) for a particular spawning run from a list of "valid" PIT tags. Observation data are then "cleaned up" using the `PITcleanr` R package to determine a final destination or spawning location for each individual and prepared for use in the `DABOM` R package and model. Next, we describe how to write a JAGS model for use in the `DABOM` model, and finally, run `DABOM` to estimate detection and transition probabilities in the Yakima River system. Movement probabilities can then be multiplied by estimates of adult escapement at Prosser Dam to estimate escapement at any observation site (or tributary) within the Yakima River. 

# Set-up

The first step is to ensure all of the appropriate software and R packages are installed on your computer. R is simply a language and environment for statistical computing and graphics and is the workhorse for running all of the models described herein; R packages are collections of functions and data sets developed by the R community for particular tasks. Some R packages used here are available from the general R community and some (e.g., `DABOM`) are developed by Kevin See and contain function specifically for analysis of PIT observation data.

First, you will need to have [R](https://cran.r-project.org/) downloaded and installed. You can download and install the "base" distribution and all of the default installation settings should work just fine. In addition, we find it useful to use [RStudio](https://rstudio.com/) to interface with R. Again, download and install the Desktop version of RStudio using the default settings. RStudio provide a graphical user interface (GUI) for R and provide a text/code editor, allows for direct code execution, management of R packages, and allows you to view R objects (e.g., data) in your environment.

Next, you will also need the [JAGS](http://mcmc-jags.sourceforge.net/) software to run DABOM. You can download that from [SourceForge](https://sourceforge.net/projects/mcmc-jags/files/). 

After installing R and RStudio, you will also need to install `tidyverse`, a series of R packages that work together for data science (e.g., data cleaning and wrangling), as well as the `jagsUI` package to interface with the JAGS (Just Another Gibbs Sampler) software which is used by `DABOM` for Bayian inference. The `tidyverse` and `jagsUI` packages are both available from the R community and can be installed by typing the following into your R console:

```{r install-cran, eval = F}
install.packages("tidyverse")
install.packages("jagsUI")
```

You will then need to install a few custom packages written for this model. The first is called `PITcleanr` written primarily for clean PIT tag observation data. And `DABOM` is used for writing and running the DABOM model. You can use the `devtools` package to install both from [GitHub](https://github.com/) using the following code:

```{r install-github, eval = F}
install.packages("devtools")
devtools::install_github("KevinSee/PITcleanr")
devtools::install_github("KevinSee/DABOM")
```

NOTE: To use `devtools`, you may also have to download and install Rtools (although it may already be installed). The latest version on Rtools can be found at https://cran.r-project.org/bin/windows/Rtools/. You can try to use `devtools` without Rtools, initially, and if `PITcleanr` and `DABOM` fail to install correctly, try installing Rtools (we have had mixed results with this). Additionally, when installing `PITcleanr` or `DABOM` you may receive a messy error message containing something like *"there is no package called 'ggraph'*. In that case, try to install and load the given package using the following and then re-attempt to install `PITclean` and `DABOM`.

```{r install-load-example, eval = F}
install.package("ggraph") # to install package from R cran
# replace ggraph with the appropriate package name as needed
```

We are always trying to improve the `PITcleanr` and `DABOM` R packages to minimize these types of errors.

# Steps

Briefly, the steps to process a new year of data include: 

1. Get PIT tag information
1. Query PTAGIS for observations
1. Run PITcleanr to "clean up" observations
1. Review PITcleanr output to determine final capture histories and spawning locations
1. Prepare data for DABOM and write JAGS model
1. Run DABOM
1. Summarise results
1. Combine with estimates of adult escapement at Prosser

## Tag Information

You will need to compile a list of PIT tags in steelhead that were caught in the Prosser trap for a given spawn year, called the valid tag list. Tagged steelhead need to be a random, representative sample of the run, and so should only include tags from the trap. If a fish is caught in the trap and happens to be previously tagged, that tag can be used as part of the valid tag list. However, if a previously tagged fish (e.g. a fish tagged as a juvenile in the upper Yakima) is detected crossing Prosser, but it is not caught in the trap, it cannot be used for this analysis.

Save this list of valid tags as a text file with no headers, to make it easy to upload to a PTAGIS query.

This is also a good opportunity to compile other relevant biological or life history information for each fish in that valid tag list, such as sex, length, weight, age, origin, genetics, etc. That information may be used later to estimate, for example, sex- or age-specific abundance to locations which is useful for productivity monitoring.

## PTAGIS Query

The next step is to query PTAGIS for all detections of the fish included on the valid tag list. PTAGIS is the regional database for fish marked with PIT tags by fisheries management agencies and research organizations in the Columbia River Basin. Go to the Advanced Reporting page on the [PTAGIS website](https://www.ptagis.org/data/advanced-reporting), which can also be found under the Data tab on the PTAGIS homepage. To access Advanced Reporting, you will need a free account from PTAGIS, and to be logged in. Once on the Advanced Reporting page, select "Launch". Create your own query by selecting "Create Query Builder2 Report", and start with a "Complete Tag History" query.  

You will see several query indices on the left side of the query builder, but for the purposes of `PITclean` and `DABOM`, we only need to deal with a couple of those. First, under "1 Select Attributes" the following fields are required to work with `PITcleanr`:

* Tag
* Mark Rear Type
* Event Type
* Event Site Code
* Event Date Time
* Event Release Date Time
* Antenna
* Antenna Group Configuration

You are welcome to include other fields as well, but the ones listed above must be added. Additional fields will just be included as extra columns in your query output.

The only other required index is "2 Select Metrics", but that can remain as the default, "CTH Count".

Set up a filter for specific tags by next navigating to the "28 Tag Code - List or Text File" on the left. And then, after selecting "Tag" under "Attributes:", you should be able to click on "Import file..." under "Value:" and simply upload the .txt file you saved in the previous step with all the tag codes in the valid tag list. Under "Report Message Name:" near the bottom, name the query something appropriate, such as "PTAGIS_2018_19", and select "Run Report". Once the query has successfully completed, export the output as a .csv file (e.g. "PTAGIS_2018_19.csv") using the default settings:

* Export: Whole report
* CSV file format
* Export Report Title: unchecked
* Export filter details: unchecked
* Remove extra column: Yes

<!--
Kevin - There were minor discrepancies here between your directions and my query builder, which I wonder if stems from Windows vs. Mac. Hopefully my query builder doesn't differ from most and I changed this to something inappropriate.
-->

## Processing PTAGIS Detections

The next step is to clean up all the detections listed in the PTAGIS query. Those include every detection on every antenna, so we need to condense those to a single detection on a particular array, even if the fish was detected 7 times on 3 different antennas in that array. We use the `PITcleanr` package for this. There are few parts to this particular step. The first is to load the appropriate packages into your R environment. 

```{r}
library(PITcleanr)
library(tidyverse)
```

### Site Configuration

The next step is to define which sites we are going to include in the DABOM model. The `PITcleanr` package has a special function, specific to Prosser Dam and the Yakima River, to do this, called `writePRONodeNetwork()`. This function lists all the various sites by their PTAGIS site ID code, and shows which other sites a tag would need to pass in order to reach that particular site. The below saves a new object `site_df` contaning that information. You can use the `view()` function in R to view the `site_df` object in a new window in RStudio to review the river network.

```{r}
site_df = writePRONodeNetwork()
site_df
view(site_df)
```

The next step is to query PTAGIS for all the metadata associated with these sites. Again, `PITcleanr` includes a function to do this, `buildConfig()`, but you will need an internet connection to run this. The `buildConfig()` function returns information about each site in PTAGIS, including the site code, the various configuration codes, the antenna IDs, when that configuration started and ended (if it has), what type of site it is (interrogation, INT, or mark/recapture/recover, MRR), the site name, the antenna group each antenna is part of, and several other pieces of information. It also assigns a model node to each antenna. These nodes are essentially which array each antenna is part of within each site. If it is a single array (or perhaps an MRR site), all of the antennas will be assigned to the same code. If there is a double array, the antennas in the downstream array will be assigned to the "B" array, and the upstream antennas to the "A" array. If there is a triple array, by default the middle array is grouped with the upper array, to help simplify the DABOM model structure. Defining upstream and downstream arrays and nodes are a necessary step to estimate detection probabilities at double (or triple) arrays. This file is what will link the PTAGIS detections to the DABOM model nodes.

```{r}
org_config = buildConfig()
```

Note, the `org_config` object contains **every** INT and MRR detection site included in PTAGIS. You now have the opportunity to modify this configuration file however you would like, re-assigning various antennas or sites to different nodes. For this version of DABOM, we have some suggestions, such as grouping all of the various sites on the Teanaway River into a single node called "TEAN". Many of the modifications below help simplify the nodes downstream of Prosser.

```{r}
configuration = org_config %>%
  mutate(Node = if_else(SiteID %in% c('PRO'),
                        'PRO',
                        Node),
         Node = if_else(SiteID %in% c("NFTEAN", "TEANAR", "TEANM", "TEANWF"),
                       "LMTA0",
                       Node),
         Node = if_else(SiteID == 'ROZ',
                        if_else(AntennaID %in% c('01', '02', '03'),
                                Node,
                                as.character(NA)),
                        Node),
         Node = if_else(SiteID == 'TAN' & ConfigID %in% c(120, 130),
                        "TANB0",
                        Node),
         Node = if_else(SiteID %in% c('MC1', 'MC2', 'MCJ', 'MCN'),
                       'MCN',
                       Node),
         Node = if_else(SiteID == 'ICH',
                       'ICHB0',
                       Node),
         Node = if_else(grepl('522\\.', RKM) & RKMTotal > 538,
                       'ICHA0',
                       Node),
         Node = if_else(SiteID == 'JD1',
                       'JD1B0',
                       Node),
         Node = if_else(SiteID %in% c('30M', 'BR0', 'JDM', 'SJ1', 'SJ2', 'MJ1'),
                       'JD1A0',
                       Node),
         Node = if_else(SiteID != 'JD1' & as.integer(stringr::str_split(RKM, '\\.', simplify = T)[,1]) < 351,
                       'BelowJD1',
                       Node),
         Node = if_else(SiteID == 'PRA',
                        'PRAB0',
                        Node),
         Node = if_else(SiteID != 'PRA' & as.integer(stringr::str_split(RKM, '\\.', simplify = T)[,1]) >= 639,
                        'PRAA0',
                        Node))
```

### Parent-Child Table

The next step is to build a parent-child table that describes which nodes are upstream of which nodes. In our case, when modeling returning adults, the parent node is the first node the adult crosses when returning upstream to spawn and the child node is the next node upstream. The `PITcleanr` function `createParentChildDf()` does this, taking as inputs the data frame of sites in our model, and the configuration file we just created. The other input is the starting date (in `YYYYMMDD` format) for this model run, because the function uses that to find the appropriate configuration of the antennas. For this version, we define that starting date as July 1 of the year prior to the spawn year we are interested in.

```{r}
# which spawn year are we dealing with?
yr = 2019
# start date is July 1 of the previous year
start_date = paste0(yr - 1, '0701')

# build parent-child table
parent_child = createParentChildDf(site_df,
                                   configuration,
                                   startDate = start_date)

```

### Clean PTAGIS Data

The final step of this process is run the PTAGIS detections through a `PITcleanr` function, `processCapHist_PRO`, that will assign each detection to a node in the model, and then collapse the output so we are left with only one detection on a node before that tag is sighted on a different node. 

```{r}
# get raw observations from PTAGIS
# These come from running a saved query on the list of tags to be used
observations = read_csv(paste0('../data/raw_data/PTAGIS/PTAGIS_', yr-1, '_', str_sub(as.character(yr), 3, 4), '.csv'))

# process those observations with PITcleanr, using Yakima-specific function
proc_list = processCapHist_PRO(start_date,
                               configuration = configuration,
                               parent_child = parent_child,
                               observations = observations,
                               # use this to filter out observations past July 1
                               last_obs_date = format(lubridate::ymd(start_date) + lubridate::years(1), "%Y%m%d"),
                               site_df = site_df,
                               save_file = F)
```

The output of the `processCapHist_PRO` function (`proc_list` in the code above) is a list, containing two elements:

* *NodeOrder*: a data frame containing each node in the model, the node order (how many nodes to cross to arrive there), the "path" a tag would take to get there, consisting of all the nodes it could be detected at along the way, which site that node is associated with, and the RKM of that site from PTAGIS metadata. 
* *ProcCapHist*: The "cleaned" capture histories, with a row for each detection that has been kept. It shows the tag ID, the date that tag was in the trap, the first and last observed date and time on that node, the PTAGIS site ID associated with that node, whether the tag was moving upstream or downstream, based on the previous observation, and two columns containing "ProcStatus" for "processed status". "AutoProcStatus" is `PITcleanr`'s best guess as to whether the observation on that node should be kept (`TRUE`) or discarded (`FALSE`). "UserProcStatus" is where the end user can define that for themselves. 

After this step, the results of *ProcCapHist* can be saved to an Excel file, to be examined by a fisheries biologist.

## Examine PITcleanr Output

For all the tags with no issues (detections move steadily upstream), the UserProcStatus has been set to `TRUE`. All the tags with potential detection questions have a blank in the UserProcStatus column for all the detections for that tag. So a user merely needs to open the Excel file, and filter on the UserProcStatus column, selecting all the rows where it is blank. Initially, that will include all the detections for those tags. By examining the dates and the nodes, and possibly considering the suggestion made by the AutoProcStatus column, the user needs to fill in each blank with either `TRUE` or `FALSE`, to show whether the detection at that node should be kept for the DABOM model.

One of the assumptions in the DABOM model is that fish are making a one-way upstream migration, which ends in their spawning location. So if a fish is detected moving past the SAT array for example, and later is seen moving past the SUN site, both of those observations cannot be kept in the model. Based on the dates, the user will need to decide where the final spawning location was for that fish. If it was past SUN, then the rows where the SiteID is SAT should be marked `FALSE` in the UserProcStatus columm, and the other ones marked `TRUE`. Instead, if it appears the fish spawned in Status Creek, then the SUN rows should be marked `FALSE`. The default taken by the AutoProcStatus column is to keep the latest observation, so it would default to keeping the SUN observations and dropping the SAT ones. (See example in Table \@ref(tab:ptagis-examp))

```{r ptagis-examp, echo = F}
proc_list[[2]] %>%
  filter(TagID == TagID[1]) %>%
  select(TagID:lastObsDate, SiteID, Node) %>%
  bind_rows(tibble(TagID = proc_list[[2]]$TagID[1],
                   TrapDate = proc_list[[2]]$TrapDate[1],
                   ObsDate = c(lubridate::ymd_hms("20180930_13:22:45"),
                               lubridate::ymd_hms("20180930_13:24:13")),
                   SiteID = 'SAT',
                   Node = c('SATB0', 'SATA0')) %>%
              mutate(lastObsDate = ObsDate)) %>%
  arrange(ObsDate) %>%
  mutate(AutoProcStatus = c(TRUE, rep(FALSE, 2), rep(TRUE, 6))) %>%
  kable(caption = "Example of PITcleanr output for one PIT tag.")
  
```

## Prepare and Run DABOM

