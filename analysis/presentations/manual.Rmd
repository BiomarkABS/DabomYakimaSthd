---
title: "Using DABOM for Yakima Steelhead"
author:
  - Kevin See:
      email: Kevin.See@merck.com
      institute: [biomark]
      correspondence: true
  - Mike Ackerman:
      email: Mike.Ackerman@merck.com
      institute: [biomark]
institute:
  - biomark: Biomark, Inc. 705 South 8th St., Boise, Idaho, 83702, USA
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    bookdown::html_document2:
      fig_caption: yes
      fig_height: 6
      fig_width: 6
      toc: yes
      toc_depth: 3
      toc_float:
        collapsed: yes
        smooth_scroll: yes
      theme: simplex
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks.lua
      - --lua-filter=../templates/pagebreak.lua
    bookdown::pdf_document2:
      fig_caption: yes
      fig_height: 5
      fig_width: 6
      toc: yes
      includes:
        in_header: ../templates/header_ABS.tex
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks2.lua
      - --lua-filter=../templates/pagebreak.lua
    bookdown::word_document2:
      fig_caption: yes
      fig_height: 4
      fig_width: 6
      toc: yes
      reference_docx: "../templates/ReportTemplate.docx" # Insert path for the DOCX file
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks.lua
      - --lua-filter=../templates/pagebreak.lua
bibliography:
# - ../paper/packages.bib
- ../paper/references.bib
csl: "../templates/american-fisheries-society.csl" # Insert path for the bib-style
abstract: |
  This manual contains the instructions to run the DABOM model for steelhead in the Yakima basin.
keywords: |
  keyword 1; keyword 2; keyword 3
highlights: |
  These are the highlights.
---

# Introduction

This manual describes how to run the **D**am **A**dult **B**ranch **O**ccupancy **M**odel ([DABOM](https://github.com/KevinSee/DABOM)) for steelhead crossing over Prosser Dam and into the Yakima River. We start by describing how to query [PTAGIS](https://www.ptagis.org/) to get all detections of adults at relevant observation sites (e.g., weirs, PIT tag arrays, etc.) for a particular spawning run from a list of "valid" PIT tags. Observation data are then "cleaned up" using the `PITcleanr` R package to determine a final destination or spawning location for each individual and prepared for use in the `DABOM` R package and model. Next, we describe how to write a JAGS model for use in the `DABOM` model, and finally, run `DABOM` to estimate detection and transition probabilities in the Yakima River system. Movement probabilities can then be multiplied by estimates of adult escapement at Prosser Dam to estimate escapement at any observation site (or tributary) within the Yakima River. 

# Set-up

The first step is to ensure all of the appropriate software and R packages are installed on your computer. R is simply a language and environment for statistical computing and graphics and is the workhorse for running all of the models described herein; R packages are collections of functions and data sets developed by the R community for particular tasks. Some R packages used here are available from the general R community and some (e.g., `DABOM`) are developed by Kevin See and contain function specifically for analysis of PIT observation data.

First, you will need to have [R](https://cran.r-project.org/) downloaded and installed. You can download and install the "base" distribution and all of the default installation settings should work just fine. In addition, we find it useful to use [RStudio](https://rstudio.com/) to interface with R. Again, download and install the Desktop version of RStudio using the default settings. RStudio provide a graphical user interface (GUI) for R and provide a text/code editor, allows for direct code execution, management of R packages, and allows you to view R objects (e.g., data) in your environment.

Next, you will also need the [JAGS](http://mcmc-jags.sourceforge.net/) software to run DABOM. You can download that from [SourceForge](https://sourceforge.net/projects/mcmc-jags/files/). 

After installing R and RStudio, you will also need to install `tidyverse`, a series of R packages that work together for data science (e.g., data cleaning and wrangling), as well as the `jagsUI` package to interface with the JAGS (Just Another Gibbs Sampler) software which is used by `DABOM` for Bayian inference. The `tidyverse` and `jagsUI` packages are both available from the R community and can be installed by typing the following into your R console:

```{r install-cran, eval = F}
install.packages("tidyverse")
install.packages("jagsUI")
```

You will then need to install a few custom packages written for this model. The first is called `PITcleanr` written primarily for clean PIT tag observation data. And `DABOM` is used for writing and running the DABOM model. You can use the `devtools` package to install both from [GitHub](https://github.com/) using the following code:

```{r install-github, eval = F}
install.packages("devtools")
devtools::install_github("KevinSee/PITcleanr")
devtools::install_github("KevinSee/DABOM")
```

NOTE: To use `devtools`, you may also have to download and install Rtools (although it may already be installed). The latest version on Rtools can be found at https://cran.r-project.org/bin/windows/Rtools/. You can try to use `devtools` without Rtools, initially, and if `PITcleanr` and `DABOM` fail to install correctly, try installing Rtools (we have had mixed results with this). Additionally, when installing `PITcleanr` or `DABOM` you may receive a messy error message containing something like *"there is no package called 'ggraph'*. In that case, try to install and load the given package using the following and then re-attempt to install `PITclean` and `DABOM`.

```{r install-load-example, eval = F}
install.package("ggraph") # to install package from R cran
library(ggraph)           # to load the package into your R environment
# replace ggraph with the appropriate package name as needed
```

We are always trying to improve the `PITcleanr` and `DABOM` R packages to minimize these types of errors.

# Steps

Briefly, the steps for a new year of data include: 

1. Get tag information
1. Query PTAGIS for observations
1. Run PITcleanr to "clean up" observations
1. Refine PITcleanr output
1. Prepare data for DABOM and write JAGS model
1. Run DABOM
1. Summarise results
1. Combine with estimates of adult escapement at Prosser

## Tag Information

You will need to compile a list of PIT tags that were caught in the Prosser trap for that spawn year, called the valid tag list. These need to be a random, representative sample of the run, so it should only include tags from the trap. If a fish is caught in the trap and happens to be previously tagged, that tag can be used as part of the valid tag list. However, if a previously tagged fish (e.g. a fish tagged as a juvenile in the upper Yakima) is detected crossing Prosser, but is not caught in the trap, it cannot be used for this analysis.

Save this list of valid tags as a text file with no headers, to make it easy to upload to a PTAGIS query.

This is a good opportunity to compile other relevant biological information for the fish in that valid tag list, such as sex, length, weight and origin. 

## PTAGIS Query

The next step is to query PTAGIS for all detections of the fish on the valid tag list. Go to the Advanced Reporting tab on the [PTAGIS website](https://www.ptagis.org/data/advanced-reporting). You will need a free account from PTAGIS, and to be logged in. Select "Launch". Create your own query by selecting "Create Query Builder2 Report", and start with a "Complete Tag History" query. 

The following fields are required to work with `PITcleanr`:

* Tag
* Mark Rear Type
* Event Type
* Event Site Code
* Event Date Time
* Event Release Date Time
* Antenna
* Antenna Group Configuration

You are welcome to include other fields as well, but the ones listed above must be added.

Set up a filter for specific tags by clicking on "27 Tag Code - List or Text File" on the right. Select "Import file..." and upload the file you saved in the previous step with all the tag codes in the valid tag list. Name the query something appropriate, such as "PTAGIS_2018_19", and select "Run Report".

Once the query has been run, 
